{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ce138a-ac1b-417a-8fc4-4a2eec1f4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "from lib.linear_algebra import Matrix\n",
    "from lib.nn import Linear, ReLU, NN, Sigmoid, Embedding, Flatten, MaxPooling\n",
    "from lib.tokenization import BPETokenizer\n",
    "from lib.io import load_tokenizer, save_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb8375b-2e86-4d7c-ad96-15113163f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "# This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing.\n",
    "tokenizer_data = []\n",
    "read_header = False\n",
    "assert len(\"negative\") == len(\"positive\")\n",
    "label_len = len(\"negative\") + 1\n",
    "with open(\"data/imdb_dataset.csv\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        if not read_header:\n",
    "            read_header = True\n",
    "            continue\n",
    "        tokenizer_data.append([line[:-label_len - 1], line[-label_len:-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7da1f93-0d13-4e1b-9459-60feeef17014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = BPETokenizer(3000)\n",
    "# tokenizer.fit([d[0] for d in tokenizer_data])\n",
    "# save_tokenizer(tokenizer, \"imdb_tokenizer_3K\")\n",
    "\n",
    "tokenizer = load_tokenizer(\"imdb_tokenizer_3K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7332f2a-82be-4545-8d4d-316dc7a15648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipkart Customer Review and Rating\n",
    "# This Dataset consists of reviews by customers on boAt Rockerz 400\n",
    "\n",
    "data = []\n",
    "read_header = False\n",
    "with open(\"data/flipkart_reviews.csv\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        if not read_header:\n",
    "            read_header = True\n",
    "            continue\n",
    "        data.append([line[:-12], int(int(line[-2])>=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd0cfaa-4a73-488b-989a-d4eb3dceeb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [d for d in data if d[1]==1][:500] + [d for d in data if d[1]==0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e01fbbf-b20f-44a5-8498-e7a95fb69eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool() as pool:\n",
    "    tokens_list = pool.map(tokenizer.encode, [d[0] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd5569a-8ea3-45d6-b0d6-6e22ce5a445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d[1] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d99904f-b5a2-4ce3-bc48-60665031f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "for tokens in tokens_list:\n",
    "    del tokens[max_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4285d423-e281-4814-a767-22afb3d04dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ill_formatted_indices = [] \n",
    "for i, tokens in enumerate(tokens_list):\n",
    "    if any(isinstance(t, str) for t in tokens):\n",
    "        ill_formatted_indices.append(i)\n",
    "\n",
    "tokens_list = [t for i, t in enumerate(tokens_list) if i not in ill_formatted_indices]\n",
    "labels = [l for i, l in enumerate(labels) if i not in ill_formatted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdca7a57-1ec3-499e-8bd5-2ab2908e1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(tokens) for tokens in tokens_list])\n",
    "for tokens in tokens_list:\n",
    "    tokens.extend([0] * (max_len - len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6220432-c0ac-4ef1-9cdd-a7601ed81476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((771, 32), (771, 1), (193, 32), (193, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = random.sample(range(len(tokens_list)), int(len(tokens_list) * 0.8))\n",
    "X_train, y_train = Matrix([t for i, t in enumerate(tokens_list) if i in indices]), Matrix([[l] for i, l in enumerate(labels) if i in indices])\n",
    "X_test, y_test = Matrix([t for i, t in enumerate(tokens_list) if i not in indices]), Matrix([[l] for i, l in enumerate(labels) if i not in indices])\n",
    "X_train.dims(), y_train.dims(), X_test.dims(), y_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21720a5e-9e9c-4c7c-a582-dcd8aa3ef477",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "emb_size = 8\n",
    "\n",
    "size_dim, seq_len = X_train.dims()\n",
    "\n",
    "nn = NN(\n",
    "    [\n",
    "        Embedding(vocab_size, emb_size),\n",
    "        Flatten(),\n",
    "        Linear(seq_len * emb_size, 16, \"uniform_glorot\"),\n",
    "        ReLU(),\n",
    "        Linear(16, 16, \"uniform_glorot\"),\n",
    "        ReLU(),\n",
    "        Linear(16, 1, \"uniform_glorot\"),\n",
    "        Sigmoid(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70f207b-0efe-43e7-ad7f-555d19a6624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 0.76 | 138s\n",
      "1 | 0.69 | 544s\n",
      "2 | 0.67 | 790s\n",
      "3 | 0.66 | 746s\n",
      "4 | 0.65 | 841s\n",
      "5 | 0.64 | 685s\n",
      "6 | 0.64 | 734s\n",
      "7 | 0.63 | 811s\n",
      "8 | 0.63 | 1163s\n",
      "9 | 0.62 | 986s\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 1e-5\n",
    "time_point = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    out = nn(X_train)\n",
    "    loss = -(y_train * out.ln() + (1-y_train) * (1-out).ln()).row_sum().col_sum()[0] / y_train.dims()[0]\n",
    "\n",
    "    elapsed_time = int(time.time() - time_point)\n",
    "    print(f\"{i} | {loss.data:.2f} | {elapsed_time}s\")\n",
    "    time_point = time.time()\n",
    "\n",
    "    for p in nn.params():\n",
    "        p.zero_grad()\n",
    "    loss.grad = 1\n",
    "    loss.backward()\n",
    "\n",
    "    for p in nn.params():\n",
    "        for v in p.all_values():\n",
    "            v.data -= 0.1 * v.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b96972b-e7a7-4ea4-b66e-c4de6f15b87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{aab0614a, 0.64, 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = nn(X_test) \n",
    "loss = -(y_test * out.ln() + (1-y_test) * (1-out).ln()).row_sum().col_sum()[0] / y_test.dims()[0]\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ffd39cc-8ffe-4e0b-ab82-b14fb70d19eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5906735751295337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([round(o[0].data) == yt[0].data for o, yt in zip(out, y_test)])/y_test.dims()[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9f95202-c527-48bb-a615-447b7bbc860d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great looks n very light weight sound is very cool but design is ok ok. t',\n",
       "  np.float64(0.34),\n",
       "  1),\n",
       " ('light weight and easy to carry anywhere and attractive model awesome service from flip',\n",
       "  np.float64(0.57),\n",
       "  1),\n",
       " ('\"The boat product is good excellent headphone to buy with Bluetooth without ',\n",
       "  np.float64(0.54),\n",
       "  1),\n",
       " ('Product is good battery backup is also good. I recommend you should bu',\n",
       "  np.float64(0.63),\n",
       "  1),\n",
       " ('\"Firstly, Thanks to Flipkart...I got the headphones 4 days earlier...',\n",
       "  np.float64(0.6),\n",
       "  1),\n",
       " ('Best<SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR>',\n",
       "  np.float64(0.15),\n",
       "  0),\n",
       " ('Its too painfull on ears<SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR>',\n",
       "  np.float64(0.18),\n",
       "  0),\n",
       " ('Very bad sound quality and product is not satisfied<SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR><SEPARATOR>',\n",
       "  np.float64(0.15),\n",
       "  0),\n",
       " (\"Really bad experience.One side of the headphone and the mic  wasn't\",\n",
       "  np.float64(0.52),\n",
       "  0),\n",
       " ('It is too delicate... I widened it to wear and it broke from the top...<SEPARATOR><SEPARATOR>',\n",
       "  np.float64(0.62),\n",
       "  0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [(tokenizer.decode([t.data for t in xt]), round(o[0].data, 2), yt[0].data) for o, yt, xt in zip(out, y_test, X_test)]\n",
    "examples[:5] + examples[-5:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
