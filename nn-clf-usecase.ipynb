{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d305f180-0341-45a6-8372-29188ea2d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from lib.value import Value\n",
    "from lib.linear_algebra import Vector, Matrix\n",
    "from lib.nn import NN, Softmax, Linear\n",
    "from lib.processing import OneHotEncoder, ColumnNormalizer\n",
    "from lib.metrics.losses import negative_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d99b45-d102-4f86-ba2b-3fc6b4732e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n",
    "# It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "with open(\"data/iris.data\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        data.append([float(v) for v in line.split(\",\")[:-1]])\n",
    "        labels.append(line.split(\",\")[-1])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b375e393-c45b-4b80-9638-b8c733f6a361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = list(range(len(data)))\n",
    "np.random.shuffle(indeces)\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "X_train = data[indeces[:split]]\n",
    "X_test = data[indeces[split:]]\n",
    "y_train = [labels[i] for i in indeces[:split]]\n",
    "y_test = [labels[i] for i in indeces[split:]]\n",
    "X_train = Matrix(X_train)\n",
    "X_test = Matrix(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad713716-b457-4d51-932a-ba015a843d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 3), (30, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(labels)\n",
    "y_train = ohe.transform(y_train)\n",
    "y_test = ohe.transform(y_test)\n",
    "y_train.dims(), y_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4a5acf-6157-4196-a224-f50144fb6344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = ColumnNormalizer()\n",
    "normalizer.fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72cc6c4-edcc-40f2-a8fa-172eb5988a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN([\n",
    "    Linear(4, 3),\n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f66f69f-6592-45be-b963-3ae966069ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 1.71 | 0s\n",
      "100 | 0.92 | 17s\n",
      "200 | 0.64 | 17s\n",
      "300 | 0.55 | 17s\n",
      "400 | 0.50 | 17s\n",
      "500 | 0.47 | 18s\n",
      "600 | 0.44 | 17s\n",
      "700 | 0.42 | 18s\n",
      "800 | 0.41 | 18s\n",
      "900 | 0.39 | 18s\n",
      "1000 | 0.38 | 17s\n",
      "1100 | 0.36 | 17s\n",
      "1200 | 0.35 | 17s\n",
      "1300 | 0.34 | 17s\n",
      "1400 | 0.33 | 17s\n",
      "1500 | 0.33 | 17s\n",
      "1600 | 0.32 | 16s\n",
      "1700 | 0.31 | 15s\n",
      "1800 | 0.30 | 15s\n",
      "1900 | 0.29 | 17s\n",
      "2000 | 0.29 | 17s\n",
      "2100 | 0.28 | 17s\n",
      "2200 | 0.28 | 17s\n",
      "2300 | 0.27 | 17s\n",
      "2400 | 0.26 | 16s\n",
      "2500 | 0.26 | 16s\n",
      "2600 | 0.25 | 17s\n",
      "2700 | 0.25 | 17s\n",
      "2800 | 0.24 | 16s\n",
      "2900 | 0.24 | 16s\n",
      "3000 | 0.24 | 16s\n",
      "3100 | 0.23 | 16s\n",
      "3200 | 0.23 | 17s\n",
      "3300 | 0.22 | 17s\n",
      "3400 | 0.22 | 17s\n",
      "3500 | 0.22 | 17s\n",
      "3600 | 0.21 | 16s\n",
      "3700 | 0.21 | 16s\n",
      "3800 | 0.21 | 17s\n",
      "3900 | 0.20 | 17s\n",
      "4000 | 0.20 | 17s\n"
     ]
    }
   ],
   "source": [
    "time_point = time.time()\n",
    "\n",
    "for i in range(4001):\n",
    "    out = nn(X_train)\n",
    "    loss = negative_log_likelihood(y_train, out)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        elapsed_time = int(time.time() - time_point)\n",
    "        time_point = time.time()\n",
    "        print(f\"{i} | {loss.data:.2f} | {elapsed_time}s\")    \n",
    "\n",
    "    for p in nn.params():\n",
    "        p.zero_grad()\n",
    "    loss.grad = 1\n",
    "    loss.backward()\n",
    "\n",
    "    for p in nn.params():\n",
    "        for v in p.all_values():\n",
    "            v.data -= 0.01 * v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab993d4-0c60-44b9-904b-b8ccfadb1544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8a61a53d, 0.18, 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = nn(X_test) \n",
    "loss = negative_log_likelihood(y_test, out)\n",
    "   \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35a35ec-a1ca-4b71-886d-28d92db4588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.9, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.1, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(round(float(v1),1), float(v2)) for v1, v2 in zip([v[0].data for v in out.values], [v[0].data for v in y_test])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
