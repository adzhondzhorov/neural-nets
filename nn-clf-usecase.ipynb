{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a54d313-d375-400b-b11a-aa88d25b2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FAST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d305f180-0341-45a6-8372-29188ea2d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "if USE_FAST:\n",
    "    from lib.fast.value import Value\n",
    "    from lib.fast.linear_algebra import Vector, Matrix\n",
    "    from lib.fast.nn import NN, Softmax, Linear\n",
    "    from lib.fast.processing import OneHotEncoder, ColumnNormalizer\n",
    "else:\n",
    "    from lib.original.value import Value\n",
    "    from lib.original.linear_algebra import Vector, Matrix\n",
    "    from lib.original.nn import NN, Softmax, Linear\n",
    "    from lib.original.processing import OneHotEncoder, ColumnNormalizer\n",
    "    \n",
    "from lib.metrics.losses import negative_log_likelihood\n",
    "from lib.gd_data_loaders import BatchDataLoader, StochasticDataLoader, MiniBatchDataLoader\n",
    "from lib.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d99b45-d102-4f86-ba2b-3fc6b4732e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n",
    "# It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "with open(\"data/iris.data\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        data.append([float(v) for v in line.split(\",\")[:-1]])\n",
    "        labels.append(line.split(\",\")[-1])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b375e393-c45b-4b80-9638-b8c733f6a361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = list(range(len(data)))\n",
    "np.random.shuffle(indeces)\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "X_train = data[indeces[:split]]\n",
    "X_test = data[indeces[split:]]\n",
    "y_train = [labels[i] for i in indeces[:split]]\n",
    "y_test = [labels[i] for i in indeces[split:]]\n",
    "X_train = Matrix(X_train)\n",
    "X_test = Matrix(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad713716-b457-4d51-932a-ba015a843d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 3), (30, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(labels)\n",
    "y_train = ohe.transform(y_train)\n",
    "y_test = ohe.transform(y_test)\n",
    "y_train.dims(), y_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4a5acf-6157-4196-a224-f50144fb6344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = ColumnNormalizer()\n",
    "normalizer.fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72cc6c4-edcc-40f2-a8fa-172eb5988a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nn():\n",
    "    return NN([\n",
    "        Linear(4, 3),\n",
    "        Softmax()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f66f69f-6592-45be-b963-3ae966069ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.SgdOptimizer'>\n",
      "0 | 1.49 | 0s\n",
      "400 | 0.72 | 1s\n",
      "800 | 0.06 | 1s\n",
      "1200 | 0.05 | 1s\n",
      "1600 | 0.30 | 1s\n",
      "2000 | 0.34 | 1s\n",
      "2400 | 0.25 | 1s\n",
      "2800 | 0.47 | 1s\n",
      "3200 | 0.15 | 1s\n",
      "3600 | 0.17 | 1s\n",
      "4000 | 0.08 | 1s\n",
      "train loss: 0.20   test loss: 0.18\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.SgdWithMomentumOptimizer'>\n",
      "0 | 2.64 | 0s\n",
      "400 | 1.12 | 1s\n",
      "800 | 0.31 | 1s\n",
      "1200 | 0.23 | 1s\n",
      "1600 | 0.36 | 1s\n",
      "2000 | 0.04 | 1s\n",
      "2400 | 0.34 | 1s\n",
      "2800 | 0.32 | 1s\n",
      "3200 | 0.23 | 1s\n",
      "3600 | 0.19 | 1s\n",
      "4000 | 0.16 | 1s\n",
      "train loss: 0.21   test loss: 0.19\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.AdaGradOptimizer'>\n",
      "0 | 1.90 | 0s\n",
      "400 | 0.06 | 1s\n",
      "800 | 0.22 | 1s\n",
      "1200 | 0.41 | 1s\n",
      "1600 | 0.29 | 1s\n",
      "2000 | 0.05 | 1s\n",
      "2400 | 0.08 | 1s\n",
      "2800 | 0.13 | 1s\n",
      "3200 | 0.23 | 1s\n",
      "3600 | 0.39 | 1s\n",
      "4000 | 0.19 | 1s\n",
      "train loss: 0.12   test loss: 0.13\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.RmsPropOptimizer'>\n",
      "0 | 1.13 | 0s\n",
      "400 | 0.11 | 1s\n",
      "800 | 0.10 | 1s\n",
      "1200 | 0.14 | 1s\n",
      "1600 | 0.05 | 1s\n",
      "2000 | 0.04 | 1s\n",
      "2400 | 0.04 | 1s\n",
      "2800 | 0.07 | 1s\n",
      "3200 | 0.01 | 1s\n",
      "3600 | 0.02 | 1s\n",
      "4000 | 0.08 | 1s\n",
      "train loss: 0.04   test loss: 0.11\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.AdamOptimizer'>\n",
      "0 | 4.40 | 0s\n",
      "400 | 0.10 | 1s\n",
      "800 | 0.04 | 1s\n",
      "1200 | 0.02 | 1s\n",
      "1600 | 0.04 | 1s\n",
      "2000 | 0.02 | 1s\n",
      "2400 | 0.04 | 1s\n",
      "2800 | 0.00 | 1s\n",
      "3200 | 0.00 | 1s\n",
      "3600 | 0.46 | 1s\n",
      "4000 | 0.00 | 1s\n",
      "train loss: 0.04   test loss: 0.11\n"
     ]
    }
   ],
   "source": [
    "time_point = time.time()\n",
    "\n",
    "data_loaders = [\n",
    "    # BatchDataLoader(X_train, y_train),\n",
    "    # StochasticDataLoader(X_train, y_train),\n",
    "    MiniBatchDataLoader(X_train, y_train, 4)\n",
    "]\n",
    "optimizer_creators = [\n",
    "    lambda nn: SgdOptimizer(nn, 0.01),\n",
    "    lambda nn: SgdWithMomentumOptimizer(nn, 0.01, 0.9),\n",
    "    lambda nn: AdaGradOptimizer(nn, 0.1),\n",
    "    lambda nn: RmsPropOptimizer(nn, 0.01, 0.95),\n",
    "    lambda nn: AdamOptimizer(nn, 0.01, 0.95, 0.95),\n",
    "]\n",
    "\n",
    "for data_loader in data_loaders:\n",
    "    for optimizer_creator in optimizer_creators:\n",
    "        nn = init_nn()\n",
    "        optimizer = optimizer_creator(nn)\n",
    "        print(f\"gradient descent: {data_loader.__class__} | optimizer: {optimizer.__class__}\")\n",
    "        for i in range(4001):\n",
    "            X_b, y_b = data_loader.get_batch()\n",
    "            out = nn(X_b)\n",
    "            loss = negative_log_likelihood(y_b, out)\n",
    "            \n",
    "            if i % 400 == 0:\n",
    "                elapsed_time = int(time.time() - time_point)\n",
    "                time_point = time.time()\n",
    "                print(f\"{i} | {loss.data:.2f} | {elapsed_time}s\")    \n",
    "    \n",
    "            optimizer.step(loss)\n",
    "        \n",
    "        train_out = nn(X_train) \n",
    "        train_loss = negative_log_likelihood(y_train, train_out)\n",
    "        test_out = nn(X_test) \n",
    "        test_loss = negative_log_likelihood(y_test, test_out)\n",
    "        print(f\"train loss: {train_loss.data:.2f}   test loss: {test_loss.data:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "712c06d5-f168-41a6-8b26-f8cd1604cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1.06, -3.85},\n",
       " {0.57, -3.2},\n",
       " {1.12, -18.28},\n",
       " {1.2, -8.61},\n",
       " {-0.51, 5.36},\n",
       " {1.49, -2.0},\n",
       " {-1.29, 2.99},\n",
       " {-1.33, -0.7},\n",
       " {-1.24, 9.84},\n",
       " {-0.12, -9.23},\n",
       " {-1.35, 5.37},\n",
       " {-1.46, 2.88},\n",
       " {-0.39, -5.21},\n",
       " {-1.49, 10.74},\n",
       " {0.03, 15.59},\n",
       " {-0.13, 3.35}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b.all_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd097f-8477-4c81-b91c-3e9996d492f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
