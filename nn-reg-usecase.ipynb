{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b7cbf3-f5ab-4e76-896e-fcc8f3a3a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"original_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d305f180-0341-45a6-8372-29188ea2d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "match backend:\n",
    "    case \"original_backend\":\n",
    "        from lib.original_backend.linear_algebra import Matrix\n",
    "        from lib.original_backend.nn import  NN, ReLU, Linear, LayerNorm\n",
    "        from lib.original_backend.processing import ColumnNormalizer\n",
    "        from lib.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "    case \"np_backend\":\n",
    "        from lib.np_backend.linear_algebra import Matrix\n",
    "        from lib.np_backend.nn import NN, ReLU, Linear\n",
    "        from lib.np_backend.processing import ColumnNormalizer\n",
    "        from lib.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "    case \"pt_backend\":\n",
    "        from lib.pt_backend.linear_algebra import Matrix\n",
    "        from lib.pt_backend.nn import NN, ReLU, Linear\n",
    "        from lib.pt_backend.processing import ColumnNormalizer\n",
    "        from lib.pt_backend.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "from lib.metrics.losses import mean_squared_error\n",
    "from lib.gd_data_loaders import BatchDataLoader, StochasticDataLoader, MiniBatchDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d99b45-d102-4f86-ba2b-3fc6b4732e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston House Price Dataset\n",
    "# The Boston House Price Dataset involves the prediction of a house price in thousands of dollars given details of the house and its neighborhood.\n",
    "# It is a regression problem. There are 506 observations with 13 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "data = []\n",
    "with open(\"data/boston_house_prices.data\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        data.append([float(v) for v in line.split()])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b079e8-9f3a-4224-a611-449df789337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404, 1), (102, 13), (102, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "split = int(len(data) * 0.8)\n",
    "train_set = data[:split]\n",
    "test_set = data[split:]\n",
    "\n",
    "X_train, y_train = train_set[:, :-1], train_set[:, -1:]\n",
    "X_test, y_test = test_set[:, :-1], test_set[:, -1:]\n",
    "X_train = Matrix(X_train)\n",
    "y_train = Matrix(y_train)\n",
    "X_test = Matrix(X_test)\n",
    "y_test = Matrix(y_test)\n",
    "X_train.dims(), y_train.dims(), X_test.dims(), y_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495365f8-f306-42e6-9ba7-dc7ce463b92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = ColumnNormalizer()\n",
    "normalizer.fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72cc6c4-edcc-40f2-a8fa-172eb5988a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nn():\n",
    "    return NN([\n",
    "        Linear(13, 4),\n",
    "        LayerNorm(4),\n",
    "        ReLU(),\n",
    "        Linear(4, 1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f66f69f-6592-45be-b963-3ae966069ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.AdaGradOptimizer'>\n",
      "0 | 566.06 | 0s\n",
      "100 | 347.95 | 17s\n",
      "200 | 169.67 | 16s\n",
      "300 | 61.86 | 18s\n",
      "400 | 36.65 | 19s\n",
      "500 | 70.86 | 18s\n",
      "600 | 46.64 | 18s\n",
      "700 | 44.32 | 18s\n",
      "800 | 42.03 | 19s\n",
      "900 | 18.76 | 19s\n",
      "1000 | 27.63 | 19s\n",
      "1100 | 56.38 | 18s\n",
      "1200 | 41.77 | 18s\n",
      "1300 | 15.49 | 19s\n",
      "1400 | 38.96 | 19s\n",
      "1500 | 40.18 | 19s\n",
      "1600 | 22.58 | 18s\n",
      "1700 | 11.90 | 18s\n",
      "1800 | 47.20 | 19s\n",
      "1900 | 40.08 | 18s\n",
      "2000 | 27.74 | 18s\n",
      "train loss: 28.26   test loss: 35.57\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.RmsPropOptimizer'>\n",
      "0 | 622.73 | 2s\n",
      "100 | 160.86 | 22s\n",
      "200 | 79.02 | 22s\n",
      "300 | 28.99 | 22s\n",
      "400 | 28.99 | 23s\n",
      "500 | 15.19 | 23s\n",
      "600 | 10.82 | 24s\n",
      "700 | 13.71 | 24s\n",
      "800 | 11.04 | 23s\n",
      "900 | 11.27 | 24s\n",
      "1000 | 6.28 | 23s\n",
      "1100 | 11.39 | 24s\n",
      "1200 | 7.98 | 26s\n",
      "1300 | 9.52 | 23s\n",
      "1400 | 14.05 | 23s\n",
      "1500 | 6.35 | 22s\n",
      "1600 | 14.06 | 22s\n",
      "1700 | 14.30 | 20s\n",
      "1800 | 13.42 | 21s\n",
      "1900 | 9.18 | 22s\n",
      "2000 | 14.45 | 22s\n",
      "train loss: 11.26   test loss: 7.58\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.optimizers.AdamOptimizer'>\n",
      "0 | 524.17 | 3s\n",
      "100 | 297.13 | 22s\n",
      "200 | 141.48 | 24s\n",
      "300 | 23.65 | 24s\n",
      "400 | 30.38 | 24s\n",
      "500 | 33.07 | 23s\n",
      "600 | 23.59 | 22s\n",
      "700 | 28.88 | 23s\n",
      "800 | 35.89 | 23s\n",
      "900 | 31.14 | 22s\n",
      "1000 | 29.65 | 22s\n",
      "1100 | 16.65 | 22s\n",
      "1200 | 33.81 | 23s\n",
      "1300 | 15.22 | 22s\n",
      "1400 | 13.80 | 22s\n",
      "1500 | 4.66 | 23s\n",
      "1600 | 9.37 | 22s\n",
      "1700 | 18.21 | 22s\n",
      "1800 | 11.50 | 22s\n",
      "1900 | 11.25 | 22s\n",
      "2000 | 32.10 | 23s\n",
      "train loss: 14.43   test loss: 8.95\n"
     ]
    }
   ],
   "source": [
    "time_point = time.time()\n",
    "\n",
    "data_loaders = [\n",
    "    # BatchDataLoader(X_train, y_train),\n",
    "    # StochasticDataLoader(X_train, y_train),\n",
    "    MiniBatchDataLoader(X_train, y_train, 32)\n",
    "]\n",
    "optimizer_creators = [\n",
    "    # lambda nn: SgdOptimizer(nn, 0.001),\n",
    "    # lambda nn: SgdWithMomentumOptimizer(nn, 0.001, 0.9),\n",
    "    lambda nn: AdaGradOptimizer(nn, 0.05),\n",
    "    lambda nn: RmsPropOptimizer(nn, 0.01, 0.95),\n",
    "    lambda nn: AdamOptimizer(nn, 0.01, 0.95, 0.95),\n",
    "]\n",
    "\n",
    "for data_loader in data_loaders:\n",
    "    for optimizer_creator in optimizer_creators:\n",
    "        nn = init_nn()\n",
    "        optimizer = optimizer_creator(nn)\n",
    "        print(f\"gradient descent: {data_loader.__class__} | optimizer: {optimizer.__class__}\")\n",
    "        for i in range(2001):\n",
    "            X_b, y_b = data_loader.get_batch()\n",
    "            out = nn(X_b)\n",
    "            loss = mean_squared_error(y_b, out)\n",
    "            if i % 100 == 0:\n",
    "                elapsed_time = int(time.time() - time_point)\n",
    "                time_point = time.time()\n",
    "                print(f\"{i} | {loss.data:.2f} | {elapsed_time}s\") \n",
    "\n",
    "            optimizer.step(loss)\n",
    "\n",
    "        train_out = nn(X_train) \n",
    "        train_loss = mean_squared_error(y_train, train_out)\n",
    "        test_out = nn(X_test) \n",
    "        test_loss = mean_squared_error(y_test, test_out)\n",
    "        print(f\"train loss: {train_loss.data:.2f}   test loss: {test_loss.data:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35a35ec-a1ca-4b71-886d-28d92db4588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(26.6, 20.7),\n",
       " (26.2, 39.8),\n",
       " (33.8, 17.8),\n",
       " (20.2, 19.6),\n",
       " (33.3, 14.9),\n",
       " (21.8, 22.0),\n",
       " (14.0, 48.8),\n",
       " (19.4, 25.0),\n",
       " (18.0, 48.5),\n",
       " (17.3, 23.9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(round(float(v1),1), float(v2)) for v1, v2 in zip([v[0].data for v in out], [v[0].data for v in y_test])][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05afd2-5c4f-47a2-ace5-997b212dac04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
