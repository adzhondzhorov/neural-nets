{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b7cbf3-f5ab-4e76-896e-fcc8f3a3a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"pt_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d305f180-0341-45a6-8372-29188ea2d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "match backend:\n",
    "    case \"original_backend\":\n",
    "        from lib.original_backend.linear_algebra import Matrix\n",
    "        from lib.original_backend.nn import  NN, ReLU, Linear, LayerNorm\n",
    "        from lib.original_backend.processing import ColumnNormalizer\n",
    "        from lib.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "    case \"np_backend\":\n",
    "        from lib.np_backend.linear_algebra import Matrix\n",
    "        from lib.np_backend.nn import NN, ReLU, Linear, LayerNorm\n",
    "        from lib.np_backend.processing import ColumnNormalizer\n",
    "        from lib.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "    case \"pt_backend\":\n",
    "        from lib.pt_backend.linear_algebra import Matrix\n",
    "        from lib.pt_backend.nn import NN, ReLU, Linear, LayerNorm\n",
    "        from lib.pt_backend.processing import ColumnNormalizer\n",
    "        from lib.pt_backend.optimizers import SgdOptimizer, SgdWithMomentumOptimizer, AdaGradOptimizer, RmsPropOptimizer, AdamOptimizer\n",
    "\n",
    "from lib.metrics.losses import mean_squared_error\n",
    "from lib.gd_data_loaders import BatchDataLoader, StochasticDataLoader, MiniBatchDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d99b45-d102-4f86-ba2b-3fc6b4732e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston House Price Dataset\n",
    "# The Boston House Price Dataset involves the prediction of a house price in thousands of dollars given details of the house and its neighborhood.\n",
    "# It is a regression problem. There are 506 observations with 13 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "data = []\n",
    "with open(\"data/boston_house_prices.data\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        data.append([float(v) for v in line.split()])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b079e8-9f3a-4224-a611-449df789337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([404, 13]),\n",
       " torch.Size([404, 1]),\n",
       " torch.Size([102, 13]),\n",
       " torch.Size([102, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "split = int(len(data) * 0.8)\n",
    "train_set = data[:split]\n",
    "test_set = data[split:]\n",
    "\n",
    "X_train, y_train = train_set[:, :-1], train_set[:, -1:]\n",
    "X_test, y_test = test_set[:, :-1], test_set[:, -1:]\n",
    "X_train = Matrix(X_train)\n",
    "y_train = Matrix(y_train)\n",
    "X_test = Matrix(X_test)\n",
    "y_test = Matrix(y_test)\n",
    "X_train.dims(), y_train.dims(), X_test.dims(), y_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495365f8-f306-42e6-9ba7-dc7ce463b92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([404, 13]), torch.Size([102, 13]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = ColumnNormalizer()\n",
    "normalizer.fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_train.dims(), X_test.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72cc6c4-edcc-40f2-a8fa-172eb5988a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nn():\n",
    "    return NN([\n",
    "        Linear(13, 4),\n",
    "        LayerNorm(4),\n",
    "        ReLU(),\n",
    "        Linear(4, 1),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f66f69f-6592-45be-b963-3ae966069ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.pt_backend.optimizers.AdaGradOptimizer'>\n",
      "0 | 575.62 | 0s\n",
      "100 | 146.36 | 0s\n",
      "200 | 143.13 | 0s\n",
      "300 | 65.19 | 0s\n",
      "400 | 59.04 | 0s\n",
      "500 | 76.57 | 0s\n",
      "600 | 20.46 | 0s\n",
      "700 | 54.61 | 0s\n",
      "800 | 24.13 | 0s\n",
      "900 | 38.33 | 0s\n",
      "1000 | 20.70 | 0s\n",
      "1100 | 17.65 | 0s\n",
      "1200 | 18.01 | 0s\n",
      "1300 | 45.34 | 0s\n",
      "1400 | 15.03 | 0s\n",
      "1500 | 37.47 | 0s\n",
      "1600 | 11.69 | 0s\n",
      "1700 | 23.82 | 0s\n",
      "1800 | 10.93 | 0s\n",
      "1900 | 7.27 | 0s\n",
      "2000 | 7.63 | 0s\n",
      "train loss: 16.16   test loss: 20.90\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.pt_backend.optimizers.RmsPropOptimizer'>\n",
      "0 | 655.30 | 0s\n",
      "100 | 141.01 | 0s\n",
      "200 | 70.01 | 0s\n",
      "300 | 30.71 | 0s\n",
      "400 | 15.11 | 0s\n",
      "500 | 9.69 | 0s\n",
      "600 | 8.05 | 0s\n",
      "700 | 16.61 | 0s\n",
      "800 | 8.11 | 0s\n",
      "900 | 12.95 | 0s\n",
      "1000 | 17.44 | 0s\n",
      "1100 | 3.89 | 0s\n",
      "1200 | 13.50 | 0s\n",
      "1300 | 14.28 | 0s\n",
      "1400 | 18.07 | 0s\n",
      "1500 | 22.07 | 0s\n",
      "1600 | 9.31 | 0s\n",
      "1700 | 5.96 | 0s\n",
      "1800 | 14.77 | 0s\n",
      "1900 | 5.53 | 0s\n",
      "2000 | 12.21 | 0s\n",
      "train loss: 10.71   test loss: 7.58\n",
      "gradient descent: <class 'lib.gd_data_loaders.MiniBatchDataLoader'> | optimizer: <class 'lib.pt_backend.optimizers.AdamOptimizer'>\n",
      "0 | 683.31 | 0s\n",
      "100 | 336.32 | 0s\n",
      "200 | 133.25 | 0s\n",
      "300 | 35.65 | 0s\n",
      "400 | 23.12 | 0s\n",
      "500 | 20.60 | 0s\n",
      "600 | 10.08 | 0s\n",
      "700 | 11.36 | 0s\n",
      "800 | 7.06 | 0s\n",
      "900 | 31.34 | 0s\n",
      "1000 | 12.70 | 0s\n",
      "1100 | 20.59 | 0s\n",
      "1200 | 11.22 | 0s\n",
      "1300 | 14.73 | 0s\n",
      "1400 | 21.38 | 0s\n",
      "1500 | 11.84 | 0s\n",
      "1600 | 8.80 | 0s\n",
      "1700 | 8.39 | 0s\n",
      "1800 | 4.19 | 0s\n",
      "1900 | 16.19 | 0s\n",
      "2000 | 4.88 | 0s\n",
      "train loss: 10.51   test loss: 7.59\n"
     ]
    }
   ],
   "source": [
    "time_point = time.time()\n",
    "\n",
    "data_loaders = [\n",
    "    # BatchDataLoader(X_train, y_train),\n",
    "    # StochasticDataLoader(X_train, y_train),\n",
    "    MiniBatchDataLoader(X_train, y_train, 32)\n",
    "]\n",
    "optimizer_creators = [\n",
    "    # lambda nn: SgdOptimizer(nn, 0.001),\n",
    "    # lambda nn: SgdWithMomentumOptimizer(nn, 0.001, 0.9),\n",
    "    lambda nn: AdaGradOptimizer(nn, 0.05),\n",
    "    lambda nn: RmsPropOptimizer(nn, 0.01, 0.95),\n",
    "    lambda nn: AdamOptimizer(nn, 0.01, 0.95, 0.95),\n",
    "]\n",
    "\n",
    "for data_loader in data_loaders:\n",
    "    for optimizer_creator in optimizer_creators:\n",
    "        nn = init_nn()\n",
    "        optimizer = optimizer_creator(nn)\n",
    "        print(f\"gradient descent: {data_loader.__class__} | optimizer: {optimizer.__class__}\")\n",
    "        for i in range(2001):\n",
    "            X_b, y_b = data_loader.get_batch()\n",
    "            out = nn(X_b)\n",
    "            loss = mean_squared_error(y_b, out)\n",
    "            if i % 100 == 0:\n",
    "                elapsed_time = int(time.time() - time_point)\n",
    "                time_point = time.time()\n",
    "                print(f\"{i} | {loss.data:.2f} | {elapsed_time}s\") \n",
    "\n",
    "            optimizer.step(loss)\n",
    "\n",
    "        train_out = nn(X_train) \n",
    "        train_loss = mean_squared_error(y_train, train_out)\n",
    "        test_out = nn(X_test) \n",
    "        test_loss = mean_squared_error(y_test, test_out)\n",
    "        print(f\"train loss: {train_loss.data:.2f}   test loss: {test_loss.data:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35a35ec-a1ca-4b71-886d-28d92db4588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32.2, 20.700000762939453),\n",
       " (11.2, 39.79999923706055),\n",
       " (21.4, 17.799999237060547),\n",
       " (27.2, 19.600000381469727),\n",
       " (23.5, 14.899999618530273),\n",
       " (22.0, 22.0),\n",
       " (20.6, 48.79999923706055),\n",
       " (15.4, 25.0),\n",
       " (21.4, 48.5),\n",
       " (31.8, 23.899999618530273)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(round(float(v1),1), float(v2)) for v1, v2 in zip([v[0].data for v in out], [v[0].data for v in y_test])][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
